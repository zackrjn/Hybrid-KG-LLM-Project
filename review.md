## Goal
1. Develop a comprehensive new research paper titled "Hybrid Vision-Textual Reasoning with Similarity-Augmented Instruction Tuning for Knowledge Graph LLMs" that advances the field of LLM-based graph reasoning specifically for Knowledge Graphs (KGs) by integrating and extending the contributions from three parent papers:
    - (1) "Similarity-based Neighbor Selection for Graph LLMs" (SNS) by Rui Li et al. (arXiv v1, last updated February 6, 2024), which introduces a training-free, inductive method using SimCSE for semantic similarity-based neighbor ranking to mitigate over-squashing and heterophily in text-attributed graphs (TAGs), achieving 3-9% accuracy improvements on datasets like Cora (citation network with 2708 nodes, 7 classes), PubMed (19717 nodes, 3 classes), Amazon-Computers (13381 nodes, 10 classes), Amazon-Photo (7487 nodes, 8 classes), Coauthor-CS (18333 nodes, 15 classes), and ogbn-arxiv (169343 nodes, 40 classes) when integrated into prompts for models like GPT-3.5-Turbo and GPT-4, outperforming vanilla GNNs and setting SOTA on PubMed via simple prompt interactions;
    - (2) "GITA: Graph to Visual and Textual Integration for Vision-Language Graph Reasoning" by Yanbin Wei et al. (arXiv v5, last updated October 31, 2024, accepted to NeurIPS 2024), which proposes an end-to-end framework incorporating visual graph representations (graph-to-image conversion using Graphviz, textual descriptions, query formulation, and VLM reasoning with models like GPT-4V and LLaVA-1.5-7B/13B) and constructs the GVLQA dataset (first vision-language QA for graphs, derived from NLGraph and GraphInstruct with base and augmented variants like GVLQA-AUGLY for layout augmentation, covering tasks such as connectivity, cycle detection, and shortest path), demonstrating superior performance over text-only LLMs on GVLQA and five real-world datasets with ablations showing layout augmentations (e.g., random, force-directed) boost results by enhancing structural intuition;
    - (3) "GraphWiz: An Instruction-Following Language Model for Graph Problems" by Nuo Chen et al. (arXiv v5, last updated July 3, 2024, published in KDD 2024), which develops GraphInstruct (72k+ instruction-tuning examples across 9 tasks like degree counting, cycle detection, shortest path, max flow, bipartite check, topology sort, triangle counting, Hamilton path, and subgraph isomorphism, generated via Erdős-Rényi graphs, GPT-4 CoT prompting, and self-augmentation with rejection sampling for diverse paths), fine-tunes base models like LLaMA2-7B/13B and Mistral-7B through mixed-task supervised fine-tuning followed by Direct Preference Optimization (DPO) to create GraphWiz-DPO (65% average accuracy vs. GPT-4's 43.8%), analyzing data volume risks (overfitting beyond thresholds) and transferability. 

Incorporate details from their GitHub repositories (verify for post-2024 updates, as repos appear static since initial releases): for SNS, outline scripts like main.py for running experiments with args --dataset (e.g., cora), --mode (tl for text+label), --k (neighbor count), call_api.py for OpenAI integration, dependencies including PyTorch 2.0, PyG, DGL, and dataset prep from LLM-Structured-Data; for GITA, describe finetune_lora_loop.sh and eval_loop.sh in /scripts for LoRA fine-tuning on LLaVA-1.5 with hyperparameters like EPOCH, BSZ, LORAR, UNFREEZEV (fine-tune vision tower), LAYOUTAUG (online augmentation), supporting tasks like connectivity and datasets in /dataset/ (GVLQA variants from Hugging Face), dependencies like torch_geometric 2.5.3 and Graphviz; for GraphWiz, detail generate_all_train_datasets.sh and generate_all_test_datasets.sh in /scripts for GraphInstruct creation, rft.sh for rejection sampling inference (20 seeds), select_path_dpo.py and find_path.py in /find_paths for path diversity (metrics: edit, jaccard, tfidf, cosine), step1_supervised_finetuning/main.py for SFT (args: --data_path, --model_name_or_path, --learning_rate 5e-6, --num_train_epochs 2), step2_dpo_training/main.py for DPO (--beta 0.5, 3 epochs), test_graph.sh for evaluation, dependencies via requirements.txt including DeepSpeed.

Use specific data like merging subsets of Cora/PubMed (for node classification), GVLQA-BASE/AUGLY (for vision QA), and GraphInstruct tasks (for instruction examples), plus new KG-specific data from sources like Wikidata or Freebase for tasks such as entity resolution, relation extraction, and multi-hop QA. To go beyond, propose a hybrid model that combines SNS's similarity-based neighbor selection (integrated into prompts as augmented subgraphs), GITA's visual graph layouts (with new adaptive augmentation based on KG density/sparsity), and GraphWiz's instruction-tuning with DPO (extended to KG domains via new hybrid instructions blending visual-textual cues), adding novel contributions like a KG-specific dataset (KG-VLInstruct, 100k+ examples augmenting GraphInstruct with visual KG renders and similarity-filtered triples), a multi-modal DPO variant favoring visually-grounded preferences, and transfer learning for unseen KG tasks; consider incorporating insights from related 2025 works like "Rethinking Graph Structure Learning" for enhanced GSL integration if relevant; encapsulate the process with training (LoRA fine-tuning on LLaVA-1.5 + Mistral backbone with mixed KG data, 2-3 epochs, batch size 4, learning rate 5e-6, using modified finetune_lora_loop.sh incorporating SNS ranking in data prep), testing/validating (80/10/10 split, cross-validation on KG benchmarks like FB15k-237 for link prediction, WN18RR for inference, with metrics accuracy/F1/MRR/Hits@10), evaluating (ablations on similarity thresholds, layout types, DPO beta=0.5, comparing to baselines like GPT-4V, GraphWiz-DPO), reviewing (discuss limitations like visual scalability for large KGs, propose future adaptive sampling), ensuring code (new repo with forked scripts: modified main.py to handle KG data loading/similarity computation, added kg_visualize.py for Graphviz-based KG rendering, hybrid_dpo.py for visual-preference optimization) serves high-level purposes like reproducible KG reasoning, and the paper structure (abstract, intro with problem gaps, related work, methodology with hybrid framework, dataset construction, experiments/results, ablations, conclusion) advances the field by enabling more interpretable, scalable, multi-modal KG LLMs.

For the code development aspect of our project, we began by forking the repositories from the three parent papers to create a unified codebase for our hybrid model. Initially, we focused on the SNS repository, where we modified main.py to incorporate knowledge graph-specific data loading by adding support for KG formats like triples from Wikidata, integrating a new function in utils.py (which we extended from the original) to compute SimCSE similarities on KG entities and relations instead of just node texts. This involved downloading subsets of Cora and ogbn-arxiv as starting points, manipulating them by injecting KG-like relations (e.g., adding entity types and predicates), and testing the modified script with --dataset kg_wikidata --mode tl --k 5 to ensure neighbor selection filtered relevant KG triples without over-squashing, which we validated by running small-scale node classification on a custom 1k-node KG subset, achieving preliminary accuracy boosts of 4-6% over the original.

Building on this, we integrated elements from the GITA repository by copying and adapting graph_to_image conversion logic (inspired by their Graphviz dependency) into a new kg_visualize.py script, which we added to our codebase. We manipulated the original GVLQA-BASE dataset by augmenting it with KG data from Freebase, creating a hybrid KG-VLQA variant with 10k examples focused on entity resolution and link prediction; this required modifying vlqa_dataset.py (extended from implied dataset handling) to include layout augmentations tailored to KG hierarchies (e.g., force-directed for sparse relations). We then updated finetune_lora_loop.sh to include our new data path and LAYOUTAUG flag, running initial pretraining on LLaVA-1.5-7B with a small epoch=1 setup on a single GPU, observing improved visual grounding in early validation sets compared to text-only baselines.

Finally, to tie it all together, we incorporated components from the GraphWiz repository, starting with generate_all_train_datasets.sh, which we modified to blend SNS-selected neighbors and GITA-visualized graphs into instruction examples for KG tasks. We extended select_path_dpo.py to prioritize diverse paths that include visual cues (e.g., adding "describe the graph image" in CoT prompts), and adapted step2_dpo_training/main.py to handle our hybrid KG data with a custom beta=0.3 for KG-specific preferences. Initial manipulations involved converting GraphInstruct subsets (e.g., shortest path, cycle detection) to KG contexts by replacing random graphs with KG subgraphs, running rft.sh with 10 seeds for rejection sampling, and evaluating on a held-out KG test set, which showed reduced overfitting risks and better transfer to unseen relations, laying the foundation for our full hybrid training pipeline.